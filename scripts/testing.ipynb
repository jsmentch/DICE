{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "93deca38-2f62-467f-ae0c-6cf5dcdce0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import deque\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "from scipy import stats\n",
    "import torch.nn as nn\n",
    "from src.utils import get_argparser\n",
    "from src.encoders_ICA import NatureCNN\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from src.lstm_attn import subjLSTM\n",
    "from src.All_Architecture import combinedModel\n",
    "\n",
    "# import torchvision.models.resnet_conv1D as models\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "from src.graph_the_works_fMRI import the_works_trainer\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import h5py\n",
    "import math\n",
    "from copy import  copy\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import torch.nn.utils.rnn as tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d146c4c-f9be-4a3b-88a7-64fbc97d9caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load my data\n",
    "with np.load('/om2/scratch/Fri/jsmentch/nat_img/sourcedata/data/HBN/brain/clean/for_dice/movieTP.npz', 'rb') as file:\n",
    "    sub_list=file['arr_0']\n",
    "    ses_list=file['arr_1']\n",
    "    dx_list=file['arr_2']\n",
    "    mmp_data=file['arr_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b38f0674-9f01-42c7-9d60-755dd4c162c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx_list.sum()\n",
    "dx_list.shape\n",
    "\n",
    "#37 with ASC; 41 NT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1da7d835-29aa-4c8f-b849-84918115f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices_of_each_class(all_labels):\n",
    "    HC_index = (dx_list == 0).nonzero()\n",
    "    SZ_index = (dx_list == 1).nonzero()\n",
    "\n",
    "    return HC_index, SZ_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a79a209-f944-4dd3-a4e0-3c7ade8edc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_argparser()\n",
    "#args = parser.parse_args()\n",
    "\n",
    "#args = parser.parse_args(args=['--req_1', '10', '--req_2', '10'])\n",
    "\n",
    "args = parser.parse_args(args=['--path', '/om2/scratch/Fri/jsmentch/dice_scratch/wandb', \n",
    "                              '--oldpath', '/om2/scratch/Fri/jsmentch/dice_scratch/wandb', \n",
    "                              '--fig-path', '/om2/scratch/Fri/jsmentch/dice_scratch/wandb', \n",
    "                              '--p-path', '/om2/scratch/Fri/jsmentch/dice_scratch/wandb', \n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba79bba4-e0ff-4c88-839b-f8e324830c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(pre_training='None', fMRI_twoD=False, deep=False, path='/om2/scratch/Fri/jsmentch/dice_scratch/wandb', oldpath='/om2/scratch/Fri/jsmentch/dice_scratch/wandb', fig_path='/om2/scratch/Fri/jsmentch/dice_scratch/wandb', p_path='/om2/scratch/Fri/jsmentch/dice_scratch/wandb', exp='NPT', gain=0.1, temperature=0.25, script_ID=1, n_test_folds_to_run=1, starting_test_fold=0, teststart_ID=1, job_ID=1, ntrials=10, sample_number=0, env_name='MontezumaRevengeNoFrameskip-v4', num_frame_stack=1, no_downsample=True, pretraining_steps=100000, probe_steps=50000, num_processes=8, method='graph_the_works', linear=True, use_multiple_predictors=False, lr=0.0002, batch_size=32, epochs=300, cuda_id=1, seed=42, encoder_type='Nature', model_type='graph_the_works', feature_size=2, fully_connected=False, feature_size_pre_training=32, fMRI_feature_size=1024, patience=15, entropy_threshold=0.6, color=False, end_with_relu=False, wandb_proj='curl-atari-neurips-scratch', num_rew_evals=10, checkpoint_index=-1, naff_fc_size=2048, pred_offset=1, sequence_length=100, steps_start=0, steps_end=99, steps_step=4, gru_size=256, lstm_size=100, lstm_size_within_window=8, fMRI_lstm_size=100, gru_layers=1, lstm_layers=1, collect_mode='random_agent', beta=1.0, weights_path='None', train_encoder=True, probe_lr=3e-06, probe_collect_mode='random_agent', num_runs=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ed169-2dd4-4318-a866-837f2edf9898",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    CUDA_LAUNCH_BLOCKING = \"1\"\n",
    "    # torch.manual_seed(33)\n",
    "    # np.random.seed(33)\n",
    "    parser = get_argparser()\n",
    "    args = parser.parse_args()\n",
    "    tags = ['pretraining-only']\n",
    "    config = {}\n",
    "    config.update(vars(args))\n",
    "    train_encoder(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092578a3-b4a9-4b46-bb16-684ffa8df1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_encoder(args):\n",
    "start_time = time.time()\n",
    "\n",
    "# ID = args.script_ID + 3\n",
    "ID = args.script_ID - 1 #? task array id...\n",
    "JobID = args.job_ID #? used for naming files\n",
    "\n",
    "\n",
    "ID = 4\n",
    "print('ID = ' + str(ID))\n",
    "print('exp = ' + args.exp)\n",
    "print('pretraining = ' + args.pre_training)\n",
    "sID = str(ID)\n",
    "currentDT = datetime.datetime.now()\n",
    "d1 = currentDT.strftime(\"%Y-%m-%d%H:%M:%S\")\n",
    "d2 = '_' + str(JobID) + '_ startFold_' + str(args.starting_test_fold) + '_' + str(args.n_test_folds_to_run)\n",
    "\n",
    "Name = args.exp + '_FBIRN_' + args.pre_training + 'DICE_Default'\n",
    "dir = 'run-' + d1 + d2 + Name\n",
    "dir = dir + '-' + str(ID)\n",
    "wdb = 'wandb_new'\n",
    "\n",
    "wpath = os.path.join(os.getcwd(), wdb)\n",
    "path = os.path.join(wpath, dir)\n",
    "args.path = path\n",
    "os.mkdir(path)\n",
    "\n",
    "wdb1 = 'wandb_new'\n",
    "wpath1 = os.path.join(os.getcwd(), wdb1)\n",
    "\n",
    "\n",
    "p = 'UF'\n",
    "dir = 'run-2019-09-1223:36:31' + '-' + str(ID) + 'FPT_ICA_COBRE'\n",
    "p_path = os.path.join(os.getcwd(), p)\n",
    "p_path = os.path.join(p_path, dir) \n",
    "args.p_path = p_path\n",
    "# os.mkdir(fig_path)\n",
    "# hf = h5py.File('../FBIRN_AllData.h5', 'w')\n",
    "tfilename = str(JobID) + 'outputFILENEWONE' + Name + str(ID)\n",
    "\n",
    "output_path = os.path.join(os.getcwd(), 'Output')\n",
    "output_path = os.path.join(output_path, tfilename)\n",
    "# output_text_file = open(output_path, \"w+\")\n",
    "# writer = SummaryWriter('exp-1')\n",
    "ntrials = args.ntrials\n",
    "ngtrials = 10\n",
    "best_auc = 0.\n",
    "best_gain = 0\n",
    "current_gain=0\n",
    "train_sub_SZ = [15, 25, 50, 75, 142, 125] #142, 132 80 #? i think tr means train not TR ?\n",
    "train_sub_HC = [15, 25, 50, 75, 134, 125] #134, 124 74 #? so training on 142/134 .. ah\n",
    "\n",
    "\n",
    "\n",
    "# With 16 per sub val, 10 WS working, MILC default\n",
    "if args.exp == 'FPT':\n",
    "    gain = [0.45, 0.05, 0.05, 0.15, 0.85]  # FPT\n",
    "elif args.exp == 'UFPT':\n",
    "    gain = [3, 3, 3, 3, 3, 3]  # UFPT\n",
    "else:\n",
    "    gain = [1, 1, 1, 1, 2.25, 1]  # NPT\n",
    "\n",
    "sub_per_class_SZ = train_sub_SZ[ID]\n",
    "sub_per_class_HC = train_sub_HC[ID]\n",
    "current_gain = gain[ID]\n",
    "args.gain = current_gain\n",
    "# sample_x = 100 #? unused ?\n",
    "sample_y = 1\n",
    "subjects = sub_list.shape[0] #78 #311\n",
    "\n",
    "# tc = 160 #? unused ?\n",
    "\n",
    "# samples_per_subject = int(tc / sample_y)\n",
    "samples_per_subject = mmp_data.shape[2]\n",
    "# samples_per_subject = int((tc - sample_y)+1)\n",
    "ntest_samples_perclass_SZ = 9\n",
    "ntest_samples_perclass_HC = 8\n",
    "if ID == 5:\n",
    "    nval_samples_perclass = 15\n",
    "else:\n",
    "    nval_samples_perclass_SZ = 9\n",
    "    nval_samples_perclass_HC = 8\n",
    "test_start_index = 0\n",
    "test_end_index = test_start_index + ntest_samples_perclass_SZ\n",
    "window_shift = 1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cudaID = str(torch.cuda.current_device())\n",
    "    print(torch.cuda.device_count())\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    device2 = torch.device(\"cuda:0\")\n",
    "    # device = torch.device(\"cuda:\" + str(args.cuda_id))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    device2 = device\n",
    "print('device = ', device)\n",
    "print('device = ', device2)\n",
    "\n",
    "\n",
    "\n",
    "n_good_comp = 53\n",
    "n_regions = 360\n",
    "\n",
    "\n",
    "\n",
    "with open('../DataandLabels/FBIRN_alldata_new_160.npz', 'rb') as file:\n",
    "    data = np.load(file)\n",
    "\n",
    "# with open('../DataandLabels/fMRI_complete_atlas_regions_116_160TC_zscore_weighted_avg_RC.npz', 'rb') as file:\n",
    "#     data = np.load(file)\n",
    "\n",
    "# with open('../../../BrainGNN/fMRI/FBIRN/fMRI_complete_atlas_regions_116_160TC_zscore_weighted_avg_RC.npz', 'rb') as file:\n",
    "#     data = np.load(file)\n",
    "\n",
    "\n",
    "# data = data * 4.0\n",
    "# print(np.max(data[:]))\n",
    "# print(np.min(data[:]))\n",
    "# print(np.mean(data[:]))\n",
    "# return\n",
    "\n",
    "\n",
    "\n",
    "data[data != data] = 0\n",
    "\n",
    "for t in range(subjects):\n",
    "    for r in range(n_regions):\n",
    "        data[t, r, :] = stats.zscore(data[t, r, :])\n",
    "\n",
    "# data = data + 2\n",
    "data = torch.from_numpy(data).float()\n",
    "finalData = np.zeros((subjects, samples_per_subject, n_regions, sample_y))\n",
    "for i in range(subjects):\n",
    "    for j in range(samples_per_subject):\n",
    "        #if j != samples_per_subject-1:\n",
    "        finalData[i, j, :, :] = data[i, :, (j * window_shift):(j * window_shift) + sample_y]\n",
    "        #else:\n",
    "            #finalData[i, j, :, :17] = data[i, :, (j * window_shift):]\n",
    "\n",
    "\n",
    "finalData2 = torch.from_numpy(finalData).float()\n",
    "selected = np.arange(311) != 73\n",
    "finalData2 = finalData2[selected,:,:,:]#torch.cat((finalData2[0:73,:,:,:], finalData2[74:,:,:,:]), dim=0)\n",
    "finalData2[finalData2 != finalData2] = 0\n",
    "\n",
    "start_path = '../Atlases2'\n",
    "count = 0;\n",
    "\n",
    "# print('starting to read data')\n",
    "# with open('../fMRI/FBIRN/fMRI_complete_FBIRN.npz', 'rb') as file:\n",
    "#     finalData2 = np.load(file)\n",
    "# print('data loaded')\n",
    "# finalData2 = torch.from_numpy(finalData2).float()\n",
    "# finalData2 = finalData2.permute(0,4,1,2,3)\n",
    "# region_data = np.zeros((311,116,140))\n",
    "# print(finalData2.shape)\n",
    "# index = 0\n",
    "# size = 0\n",
    "# for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "#     for f in sorted(filenames):\n",
    "#\n",
    "#         img = nib.load(dirpath +'/'+f)\n",
    "#         # img_np = np.array(img.dataobj)\n",
    "#         img_np = img.get_fdata(caching='unchanged')\n",
    "#         img_np = torch.from_numpy(img_np)\n",
    "#         size = size + (img_np != 0).nonzero().shape[0]\n",
    "#\n",
    "#         img_np = img_np != 0\n",
    "#         output = torch.masked_select(finalData2, img_np).reshape(311, 140, -1)\n",
    "#         output = output.sum(dim=2)\n",
    "#         region_data[:, index, :] = output\n",
    "#         index = index + 1\n",
    "#         print('index = ',index)\n",
    "#\n",
    "# print('size = ', size)\n",
    "# with open('../fMRI/FBIRN/fMRI_complete_atlas_regions_116.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, region_data)\n",
    "# print('file saved')\n",
    "# return\n",
    "\n",
    "# filename = '../DataandLabels/all_correct_indices_GSP.csv'\n",
    "# df = pd.read_csv(filename, header=None)\n",
    "# c_indices = df.values\n",
    "# c_indices = torch.from_numpy(c_indices).int()\n",
    "# c_indices = c_indices.view(100)\n",
    "# c_indices = c_indices - 1\n",
    "# finalData2 = finalData2[:, :, c_indices.long(), :]\n",
    "# n_regions = 100\n",
    "\n",
    "#     filename = '../DataandLabels/ordered_correct_indices_GSP.csv'\n",
    "#     df = pd.read_csv(filename, header=None)\n",
    "#     c_indices = df.values\n",
    "#     c_indices = torch.from_numpy(c_indices).int()\n",
    "#     c_indices = c_indices.view(53)\n",
    "#     c_indices = c_indices - 1\n",
    "\n",
    "#     # a = len(np.in1d(indices[:53],c_indices).nonzero()[0])\n",
    "#     # print(a)\n",
    "#     # return\n",
    "#     indices = np.zeros(100)\n",
    "#     indices[:53] = c_indices\n",
    "#     index = 53\n",
    "#     for l in range(100):\n",
    "#         if l in c_indices:\n",
    "#             k = 0\n",
    "#         else:\n",
    "#             indices[index] = l\n",
    "#             index = index + 1\n",
    "#     indices = torch.from_numpy(indices).long()\n",
    "# finalData2 = finalData2[:, :, indices, :]\n",
    "# n_regions = 100\n",
    "\n",
    "\n",
    "\n",
    "#     filename = '../DataandLabels/index_array_labelled_FBIRN_temp.csv'\n",
    "#     df = pd.read_csv(filename, header=None)\n",
    "#     index_array = df.values\n",
    "#     index_array = torch.from_numpy(index_array).long()\n",
    "#     index_array = index_array.view(subjects-1)\n",
    "\n",
    "#     filename = '../DataandLabels/labels_FBIRN_new.csv'\n",
    "#     df = pd.read_csv(filename, header=None)\n",
    "#     all_labels = df.values\n",
    "#     all_labels = torch.from_numpy(all_labels).int()\n",
    "#     all_labels = all_labels.view(subjects)\n",
    "#     all_labels = all_labels - 1\n",
    "#     all_labels = all_labels[selected]\n",
    "\n",
    "#     #finalData2 = finalData2[]\n",
    "# #    index_array = torch.randperm(311)\n",
    "#     finalData2 = finalData2[index_array, 0:155, :,:]\n",
    "#     all_labels = all_labels[index_array]\n",
    "#     tc = 155\n",
    "#     print(finalData2.shape)\n",
    "# return\n",
    "\n",
    "# finalData2_copy = torch.clone(finalData2)\n",
    "\n",
    "# finalData2_copy = torch.squeeze(finalData2_copy)\n",
    "# finalData2_copy = finalData2_copy.permute(0,2,1)\n",
    "# cor, rho = stats.spearmanr(finalData2[0,0,:,:],axis=1)\n",
    "# print(cor.shape)\n",
    "# return\n",
    "\n",
    "# FNC = np.zeros((subjects - 1, 4950))  # 6670\n",
    "# corrM = np.zeros((subjects-1, n_regions, n_regions))\n",
    "# for i in range(subjects - 1):\n",
    "#     corrM[i, :, :] = np.corrcoef(finalData2_copy[i])\n",
    "#     M = corrM[i, :, :]\n",
    "#     FNC[i, :] = M[np.triu_indices(n_regions, k=1)]\n",
    "# corrM = torch.from_numpy(corrM).float()\n",
    "# print (corrM[0,0,:])\n",
    "# print(FNC.shape)\n",
    "\n",
    "# report = poly(FNC, all_labels, n_folds=19, exclude=['RBF SVM'])\n",
    "# # Plot results\n",
    "# report.plot_scores()\n",
    "# return\n",
    "\n",
    "# all_labels = torch.randint(high=2, size=(311,), dtype=torch.int64)\n",
    "\n",
    "test_indices_HC = [0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136]\n",
    "test_indices_SZ = [0, 9, 18, 27, 36, 45, 54, 63, 72, 81, 90, 99, 108, 117, 126, 135, 144, 153]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "number_of_test_folds_to_run = args.n_test_folds_to_run\n",
    "n_regions_output = n_regions\n",
    "tc_after_encoder = 155 #? unused?\n",
    "HC_index, SZ_index = find_indices_of_each_class(all_labels)\n",
    "print(HC_index.shape)\n",
    "print(SZ_index.shape)\n",
    "# return\n",
    "total_test_size = ntest_samples_perclass_HC + ntest_samples_perclass_SZ\n",
    "results = torch.zeros(ntrials * number_of_test_folds_to_run, 10)\n",
    "# adjacency_matrices_FNC = torch.zeros(ntrials * number_of_test_folds_to_run, total_test_size, n_regions_output,\n",
    "#                                          n_regions_output)\n",
    "# adjacency_matrices_learned = torch.zeros(ntrials * number_of_test_folds_to_run, total_test_size, n_regions_output,\n",
    "#                                          n_regions_output)\n",
    "\n",
    "# temporal_adjacency_matrices_learned = torch.zeros(ntrials * number_of_test_folds_to_run, total_test_size, n_regions_output, tc_after_encoder,\n",
    "#                                          tc_after_encoder)\n",
    "# LR_top_adjacency_matrices_learned = torch.zeros(ntrials * number_of_test_folds_to_run, total_test_size, n_regions_output, n_regions_output)\n",
    "# LR_bottom_adjacency_matrices_learned = torch.zeros(ntrials * number_of_test_folds_to_run, total_test_size, n_regions_output, n_regions_output)\n",
    "#\n",
    "# adjacency_matrices_learned_sum = torch.zeros(ntrials * number_of_test_folds_to_run, total_test_size, n_regions_output,\n",
    "#                                              n_regions_output)\n",
    "# attention_region = torch.zeros(ntrials * number_of_test_folds_to_run, total_test_size, n_regions_output,\n",
    "#                                              tc_after_encoder)\n",
    "# attention_time = torch.zeros(ntrials * number_of_test_folds_to_run, total_test_size, tc_after_encoder)\n",
    "# attention_weights = torch.zeros(ntrials * number_of_test_folds_to_run, total_test_size, tc_after_encoder,n_regions*n_regions)\n",
    "# means_labels = torch.zeros(ntrials * number_of_test_folds_to_run, total_test_size, tc_after_encoder)\n",
    "\n",
    "# attention_components = torch.zeros(ntrials * number_of_test_folds_to_run, total_test_size, n_regions_output)\n",
    "\n",
    "# attention_time_embedding = torch.zeros(ntrials * number_of_test_folds_to_run, ntest_samples_perclass * 2, tc_after_encoder)\n",
    "# test_targets = torch.zeros(ntrials * number_of_test_folds_to_run, total_test_size)\n",
    "# test_pred = torch.zeros(ntrials * number_of_test_folds_to_run, ntest_samples_perclass * 2)\n",
    "# regions_selected = torch.zeros(ntrials * number_of_test_folds_to_run, total_test_size * 13) # 23 is the number of regions left after last pooling layer\n",
    "result_counter = 0\n",
    "for test_ID in range(number_of_test_folds_to_run):\n",
    "    # test_ID = 1\n",
    "    # index_array = torch.randperm(311)\n",
    "    # finalData2 = finalData2[index_array, :, :, :]\n",
    "    # all_labels = all_labels[index_array]\n",
    "    test_ID = test_ID + args.starting_test_fold\n",
    "    if test_ID == 17:\n",
    "        ntest_samples_perclass_SZ = 7\n",
    "        ntest_samples_perclass_HC = 14#15#14\n",
    "\n",
    "        sub_per_class_SZ = 144#134\n",
    "        sub_per_class_HC = 128#118\n",
    "\n",
    "    print('test Id =', test_ID)\n",
    "\n",
    "    test_start_index_SZ = test_indices_SZ[test_ID]\n",
    "    test_start_index_HC = test_indices_HC[test_ID]\n",
    "    test_end_index_SZ = test_start_index_SZ + ntest_samples_perclass_SZ\n",
    "    test_end_index_HC = test_start_index_HC + ntest_samples_perclass_HC\n",
    "    total_HC_index_tr_val = torch.cat([HC_index[:test_start_index_HC], HC_index[test_end_index_HC:]])\n",
    "    total_SZ_index_tr_val = torch.cat([SZ_index[:test_start_index_SZ], SZ_index[test_end_index_SZ:]])\n",
    "\n",
    "    HC_index_test = HC_index[test_start_index_HC:test_end_index_HC]\n",
    "    SZ_index_test = SZ_index[test_start_index_SZ:test_end_index_SZ]\n",
    "\n",
    "    total_HC_index_tr = total_HC_index_tr_val[:(total_HC_index_tr_val.shape[0] - nval_samples_perclass_HC)]\n",
    "    total_SZ_index_tr = total_SZ_index_tr_val[:(total_SZ_index_tr_val.shape[0] - nval_samples_perclass_SZ)]\n",
    "\n",
    "    HC_index_val = total_HC_index_tr_val[(total_HC_index_tr_val.shape[0] - nval_samples_perclass_HC):]\n",
    "    SZ_index_val = total_SZ_index_tr_val[(total_SZ_index_tr_val.shape[0] - nval_samples_perclass_SZ):]\n",
    "\n",
    "    auc_arr = torch.zeros(ngtrials, 1)\n",
    "    avg_auc = 0.\n",
    "    for trial in range(ntrials):\n",
    "            print ('trial = ', trial)\n",
    "\n",
    "        # writer.add_scalar('trial', trial)\n",
    "        # current_gain = (trial+1) * 0.05\n",
    "        # args.gain = current_gain\n",
    "        # for g_trial in range (ngtrials):\n",
    "            g_trial=1\n",
    "            output_text_file = open(output_path, \"a+\")\n",
    "            output_text_file.write(\"Test fold number = %d Trial = %d\\r\\n\" % (test_ID,trial))\n",
    "            output_text_file.close()\n",
    "            # Get subject_per_class number of random values\n",
    "            HC_random = torch.randperm(total_HC_index_tr.shape[0])\n",
    "            SZ_random = torch.randperm(total_SZ_index_tr.shape[0])\n",
    "            HC_random = HC_random[:sub_per_class_HC]\n",
    "            SZ_random = SZ_random[:sub_per_class_SZ]\n",
    "            # HC_random = torch.randint(high=len(total_HC_index_tr), size=(sub_per_class,))\n",
    "            # SZ_random = torch.randint(high=len(total_SZ_index_tr), size=(sub_per_class,))\n",
    "            #\n",
    "\n",
    "            # Choose the subject_per_class indices from HC_index_val and SZ_index_val using random numbers\n",
    "\n",
    "            HC_index_tr = total_HC_index_tr[HC_random]\n",
    "            SZ_index_tr = total_SZ_index_tr[SZ_random]\n",
    "\n",
    "            # ID = ID * ntest_samples\n",
    "            # val_indexs = ID-1;\n",
    "            # val_indexe = ID+200\n",
    "\n",
    "            tr_index = torch.cat((HC_index_tr, SZ_index_tr))\n",
    "            val_index = torch.cat((HC_index_val, SZ_index_val))\n",
    "            test_index = torch.cat((HC_index_test, SZ_index_test))\n",
    "\n",
    "            tr_index = tr_index.view(tr_index.size(0))\n",
    "            val_index = val_index.view(val_index.size(0))\n",
    "            test_index = test_index.view(test_index.size(0))\n",
    "\n",
    "            # tr_eps = finalData2[0:200, :, :, :]\n",
    "            # val_eps = finalData2[200:280, :, :, :]\n",
    "            # test_eps = finalData2[280:296, :, :, :]\n",
    "            #\n",
    "            # tr_labels = all_labels[0:200]\n",
    "            # val_labels = all_labels[200:280]\n",
    "            # test_labels = all_labels[280:296]\n",
    "\n",
    "            tr_eps = finalData2[tr_index.long(), :, :, :]\n",
    "            # tr_eps = torch.cat((finalData2[tr_index.long(), :, :, :],finalData2[test_index.long(), :, :, :]),dim=0)\n",
    "\n",
    "            val_eps = finalData2[val_index.long(), :, :, :]\n",
    "            test_eps = finalData2[test_index.long(), :, :, :]\n",
    "            # test_eps = torch.cat((finalData2[tr_index.long(), :, :, :],finalData2[val_index.long(), :, :, :],finalData2[test_index.long(), :, :, :]),dim=0)\n",
    "\n",
    "            # indexx = torch.tensor(np.array([0, 8, 1, 9, 2, 10, 3, 11, 4, 12, 5, 13, 6, 14, 7, 15]))\n",
    "            # test_eps = test_eps[indexx.long(), :, :, :]\n",
    "\n",
    "            # tr_eps2 = finalData2_copy[tr_index.long(), :, :, :]\n",
    "            # val_eps2 = finalData2_copy[val_index.long(), :, :, :]\n",
    "            # test_eps2 = finalData2_copy[test_index.long(), :, :, :]\n",
    "\n",
    "\n",
    "\n",
    "            # tr_FNC = corrM[tr_index.long(), :, :]\n",
    "            # val_FNC = corrM[val_index.long(), :, :]\n",
    "            # test_FNC = corrM[test_index.long(), :, :]\n",
    "\n",
    "            tr_labels = all_labels[tr_index.long()]\n",
    "            # tr_labels = torch.cat((all_labels[tr_index.long()],all_labels[test_index.long()]),dim=0)\n",
    "            val_labels = all_labels[val_index.long()]\n",
    "            test_labels = all_labels[test_index.long()]\n",
    "            # test_labels = torch.cat((all_labels[tr_index.long()],all_labels[val_index.long()],all_labels[test_index.long()]),dim=0)\n",
    "\n",
    "            # test_labels = test_labels[indexx.long()]\n",
    "\n",
    "\n",
    "\n",
    "            #tr_eps = torch.from_numpy(tr_eps).float()\n",
    "            #val_eps = torch.from_numpy(val_eps).float()\n",
    "            #test_eps = torch.from_numpy(test_eps).float()\n",
    "\n",
    "            # tr_labelsf = torch.cat((tr_labels, tr_labels))\n",
    "            # val_labelsf = torch.cat((val_labels, val_labels))\n",
    "            # test_labelsf = torch.cat((test_labels, test_labels))\n",
    "\n",
    "            tr_labels = tr_labels.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "            test_labels = test_labels.to(device)\n",
    "\n",
    "\n",
    "\n",
    "            tr_eps = tr_eps.to(device)\n",
    "            # val_eps = val_eps.to(device)\n",
    "            test_eps = test_eps.to(device)\n",
    "\n",
    "            # tr_eps = torch.cat((tr_eps,tr_eps),dim=0)\n",
    "            # val_eps = torch.cat((val_eps, val_eps),dim=0)\n",
    "            # test_eps = torch.cat((test_eps, test_eps),dim=0)\n",
    "\n",
    "            # tr_eps = torch.cat((tr_eps, tr_eps),dim=0)\n",
    "            # val_eps = torch.cat((val_eps, val_eps),dim=0)\n",
    "            # test_eps = torch.cat((test_eps, test_eps),dim=0)\n",
    "\n",
    "\n",
    "            # tr_epsf = torch.cat((tr_eps, tr_eps2),dim=0)\n",
    "            # val_epsf = torch.cat((val_eps, val_eps2),dim=0)\n",
    "            # test_epsf = torch.cat((test_eps, test_eps2),dim=0)\n",
    "\n",
    "            # tr_epsf = tr_epsf.permute(0,2,1,3).contiguous().reshape(292*100,160,1)\n",
    "\n",
    "\n",
    "\n",
    "            # tr_eps = tr_eps.to(device)\n",
    "            # val_eps = val_eps.to(device)\n",
    "            # test_eps = test_eps.to(device)\n",
    "\n",
    "            # print(tr_epsf.shape)\n",
    "            # tr_epsf = tr_epsf.permute(0, 2, 1, 3).contiguous().reshape(292 * 100, 160, 1)\n",
    "            # packed = tn.pack_sequence(tr_epsf, enforce_sorted=False)\n",
    "            # return\n",
    "\n",
    "            print(tr_eps.shape)\n",
    "            print(val_eps.shape)\n",
    "            print(test_eps.shape)\n",
    "\n",
    "            print(tr_labels.shape)\n",
    "            print(val_labels.shape)\n",
    "            print(test_labels.shape)\n",
    "\n",
    "            # tr_FNC = tr_FNC.to(device)\n",
    "            # val_FNC = val_FNC.to(device)\n",
    "            # test_FNC = test_FNC.to(device)\n",
    "\n",
    "\n",
    "\n",
    "            # asdfasdf = tr_eps.to(device)\n",
    "            # print('tr2', tr_eps.device, tr_eps.dtype, type(tr_eps), tr_eps.type())\n",
    "            # print('asdf',asdfasdf.device, asdfasdf.dtype, type(asdfasdf), asdfasdf.type())\n",
    "            # return;\n",
    "            # print(\"index_arrayshape\", index_array.shape)\n",
    "            #     print(\"trainershape\", tr_eps.shape)\n",
    "            #     print(\"valshape\", val_eps.shape)\n",
    "            #     print(\"testshape\", test_eps.shape)\n",
    "            #     print('ID = ', args.script_ID)\n",
    "\n",
    "            # print(tr_labels)\n",
    "            # print(test_labels)\n",
    "\n",
    "\n",
    "            observation_shape = finalData2.shape\n",
    "            L=\"\"\n",
    "            lmax=\"\"\n",
    "            number_of_graph_channels = 1\n",
    "            if args.model_type == \"graph_the_works\":\n",
    "                print('obs shape',observation_shape[3])\n",
    "                encoder = NatureCNN(observation_shape[3], args)\n",
    "\n",
    "                encoder.to(device)\n",
    "                lstm_model = subjLSTM(device, sample_y, args.lstm_size, num_layers=args.lstm_layers,\n",
    "                                      freeze_embeddings=True, gain=current_gain,bidrection=True)\n",
    "                # lstm_model_within_window = subjLSTM(device, 1, args.lstm_size_within_window, num_layers=args.lstm_layers,\n",
    "                #                       freeze_embeddings=True, gain=current_gain,bidrection=False)\n",
    "                # graph_model = Net(device2)\n",
    "                # lstm_model.to(device)\n",
    "                # graph_model.to(device2)\n",
    "                # graph2=Net2()\n",
    "                # graph_list = nn.ModuleList(\n",
    "                #     [Net(device) for _ in range(number_of_graph_channels)])\n",
    "                dir = \"\"\n",
    "                if args.pre_training == \"DECENNT\":\n",
    "                    dir = 'Pre_Trained/DECENNT/UsingHCP500TP/model.pt'\n",
    "                    args.oldpath = wpath1 + '/Pre_Trained/DECENNT/UsingHCP500TP'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            complete_model = combinedModel(encoder,lstm_model, samples_per_subject, gain=current_gain, PT=args.pre_training, exp=args.exp, device_one=device, oldpath=args.oldpath,n_regions=n_regions,device_two=device2,device_zero=device2,device_extra=device2 )\n",
    "            complete_model.to(device)\n",
    "            # if args.exp in ['UFPT', 'FPT']:\n",
    "            #    model_dict = torch.load(path, map_location=device)\n",
    "            #    complete_model.load_state_dict(model_dict)\n",
    "\n",
    "            # torch.set_num_threads(1)\n",
    "            config = {}\n",
    "            config.update(vars(args))\n",
    "            # print(\"trainershape\", os.path.join(wandb.run.dir, config['env_name'] + '.pt'))\n",
    "            config['obs_space'] = observation_shape  # weird hack\n",
    "            if args.method == \"graph_the_works\":\n",
    "                trainer = the_works_trainer(complete_model, config, device=device2, device_encoder=device,\n",
    "                                            tr_labels=tr_labels,\n",
    "                                      val_labels=val_labels, test_labels=test_labels, trial=str(trial),\n",
    "                                            crossv=str(test_ID),gtrial=str(g_trial))\n",
    "\n",
    "            else:\n",
    "                assert False, \"method {} has no trainer\".format(args.method)\n",
    "            # xindex = (ntrials * test_ID) + trial\n",
    "            # results[result_counter][0], results[result_counter][1], results[result_counter][2], \\\n",
    "            # results[result_counter][3], results[result_counter][4], results[result_counter][5], \\\n",
    "            # results[result_counter][6], results[result_counter][7],results[result_counter][8], \\\n",
    "            # results[result_counter][9], adjacency_matrices_learned[result_counter, :, :,:], \\\n",
    "            # adjacency_matrices_learned_sum[result_counter, :, :, :], \\\n",
    "            # attention_time[result_counter, :, :], LR_top_adjacency_matrices_learned[result_counter, :, :, :], \\\n",
    "            # LR_bottom_adjacency_matrices_learned[result_counter, :, :, :] = trainer.train(tr_eps, val_eps, test_eps)\n",
    "\n",
    "            # , adjacency_matrices_learned[result_counter, :, :, :], \\\n",
    "            #   adjacency_matrices_learned_sum[result_counter, :, :, :], \\\n",
    "            #   attention_time[result_counter, :, :], attention_weights[result_counter, :, :, :], \\\n",
    "            #   test_targets[result_counter, :]\n",
    "            results[result_counter][0], results[result_counter][1], results[result_counter][2], \\\n",
    "            results[result_counter][3],results[result_counter][4],\\\n",
    "            results[result_counter][5], _ = trainer.train(tr_eps, val_eps, test_eps)\n",
    "\n",
    "            result_counter = result_counter + 1\n",
    "            tresult_csv = os.path.join(args.path, 'test_results' + sID + '.csv')\n",
    "            np.savetxt(tresult_csv, results.numpy(), delimiter=\",\")\n",
    "\n",
    "# , LR_top_adjacency_matrices_learned[result_counter, :, :, :], \\\n",
    "#   LR_bottom_adjacency_matrices_learned[result_counter, :, :, :]\n",
    "        # auc_arr[g_trial] = trainer.train(tr_eps, val_eps, test_eps)\n",
    "        # return\n",
    "\n",
    "    # avg_auc = auc_arr.mean()\n",
    "    # if avg_auc > best_auc:\n",
    "    #   best_auc = avg_auc\n",
    "    #   best_gain = current_gain\n",
    "np_results = results.numpy()\n",
    "auc = np_results[:,1]\n",
    "acc = np_results[:, 0]\n",
    "print('mean test auc = ', np.mean(acc[:]))\n",
    "print('mean test acc = ', np.mean(auc[:]))\n",
    "\n",
    "# print(np.mean(auc[:]) * ((3 * 17) + 21))\n",
    "#\n",
    "# LR_auc = np_results[:, 4]\n",
    "# print(np.mean(LR_auc[:]))\n",
    "#\n",
    "# LR_acc = np_results[:, 5]\n",
    "# print(np.mean(LR_acc[:]))\n",
    "\n",
    "# np_adjacency_matrices = adjacency_matrices_learned.numpy()\n",
    "\n",
    "# print('fiinal shape ',temporal_adjacency_matrices_learned.shape)\n",
    "# np_temporal_adjacency_matrices = temporal_adjacency_matrices_learned.numpy()\n",
    "# np_LR_top_adjacency_matrices_learned = LR_top_adjacency_matrices_learned.numpy()\n",
    "# np_LR_bottom_adjacency_matrices_learned = LR_bottom_adjacency_matrices_learned.numpy()\n",
    "# np_adjacency_matrices_sum = adjacency_matrices_learned_sum.numpy()\n",
    "# np_attention_region = attention_region.numpy()\n",
    "# np_attention_time = attention_time.numpy()\n",
    "# np_attention_weights = attention_weights.numpy()\n",
    "# np_means_labels = means_labels.numpy()\n",
    "# np_attention_components = attention_components.numpy()\n",
    "# np_attention_time_embedding = attention_time_embedding.numpy()\n",
    "# np_adjacency_matrices_FNC = adjacency_matrices_FNC.numpy()\n",
    "# np_test_targets = test_targets.numpy()\n",
    "# np_test_pred = test_pred.numpy()\n",
    "# np_regions_selected = regions_selected.numpy()\n",
    "tresult_csv = os.path.join(args.path, 'test_results' + sID + '.csv')\n",
    "np.savetxt(tresult_csv, np_results, delimiter=\",\")\n",
    "# with open('../fMRI/Transformer/ICA/FBIRN/position_encoding/temporaladjacencymatrix'+str(JobID)+'.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_temporal_adjacency_matrices)\n",
    "\n",
    "# with open('../fMRI/FBIRN/AdjacencyMatrices/DICE/adjacencymatrix' + str(JobID) + '.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_adjacency_matrices)\n",
    "# with open('../fMRI/FBIRN/AdjacencyMatrices/LR/np_top_adjacency_matrices_learned'+str(JobID)+'.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_LR_top_adjacency_matrices_learned)\n",
    "# with open('../fMRI/FBIRN/AdjacencyMatrices/LR/np_bottom_adjacency_matrices_learned'+str(JobID)+'.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_LR_bottom_adjacency_matrices_learned)\n",
    "\n",
    "# with open('../fMRI/FBIRN/AdjacencyMatrices/LR/adjacencymatrix_sum'+str(JobID)+'.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_adjacency_matrices_sum)\n",
    "\n",
    "# with open('../fMRI/FBIRN/AdjacencyMatrices/np_attention_region'+str(JobID)+'.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_attention_region)\n",
    "\n",
    "# with open('../fMRI/FBIRN/AdjacencyMatrices/LR/np_attention_time'+str(JobID)+'.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_attention_time)\n",
    "\n",
    "# with open('../fMRI/FBIRN/AdjacencyMatrices/LR/np_attention_weights'+str(JobID)+'.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_attention_weights)\n",
    "\n",
    "# with open('../fMRI/FBIRN/AdjacencyMatrices/LR/np_means_labels'+str(JobID)+'.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_means_labels)\n",
    "\n",
    "# with open('../fMRI/FBIRN/AdjacencyMatrices/np_attention_components'+str(JobID)+'.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_attention_components)\n",
    "\n",
    "# with open('../fMRI/FBIRN/AdjacencyMatrices/np_attention_time_embedding'+str(JobID)+'.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_attention_time_embedding)\n",
    "# with open('../fMRI/FBIRN/AdjacencyMatrices/adjacencymatrix_FNC'+str(JobID)+'.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_adjacency_matrices_FNC)\n",
    "# with open('../fMRI/FBIRN/AdjacencyMatrices/testtargets'+str(JobID)+'.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_test_targets)\n",
    "# with open('../fMRI/FBIRN/AdjacencyMatrices/testpred'+str(JobID)+'.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_test_pred)\n",
    "# with open('../fMRI/FBIRN/AdjacencyMatrices/LR/regions'+str(JobID)+'.npz', 'wb') as filesim:\n",
    "#     np.save(filesim, np_regions_selected)\n",
    "\n",
    "#\n",
    "# return encoder\n",
    "# print ('best gain = ', best_gain)\n",
    "# output_text_file = open(output_path, \"a+\")\n",
    "# output_text_file.write(\"best gain = %f \\r\\n\" % (best_gain))\n",
    "# output_text_file.close()\n",
    "elapsed = time.time() - start_time\n",
    "print('total time = ', elapsed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde977f-8312-4dbd-ad0c-2cd9b535e6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80891e9-ee40-45ae-8a43-ecba9a15cff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d396e9c2-419f-45cd-9826-7b3194fd599c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
