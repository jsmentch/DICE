{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7730ffde-0d50-478f-b95b-8cc361f54620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import deque\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "from scipy import stats\n",
    "import torch.nn as nn\n",
    "from src.utils import get_argparser\n",
    "from src.encoders_ICA import NatureCNN\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from src.lstm_attn import subjLSTM\n",
    "from src.All_Architecture import combinedModel\n",
    "\n",
    "# import torchvision.models.resnet_conv1D as models\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "from src.graph_the_works_fMRI import the_works_trainer\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import h5py\n",
    "import math\n",
    "from copy import  copy\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import torch.nn.utils.rnn as tn\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5423c012-659e-40b4-a805-5ad135f0829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load my data\n",
    "with np.load('/om2/scratch/Fri/jsmentch/nat_img/sourcedata/data/HBN/brain/clean/for_dice/movieTP.npz', 'rb') as file:\n",
    "    sub_list=file['arr_0']\n",
    "    ses_list=file['arr_1']\n",
    "    dx_list=file['arr_2']\n",
    "    mmp_data=file['arr_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8716c64-f2bb-4e95-82bb-c3171547a772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx_list.sum()\n",
    "dx_list.shape\n",
    "\n",
    "#37 with ASC; 41 NT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "879d3855-0a9d-42ec-8e01-bf19a0b89de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices_of_each_class(dx_list):\n",
    "    HC_index = (dx_list == 0).nonzero()[0]\n",
    "    SZ_index = (dx_list == 1).nonzero()[0]\n",
    "\n",
    "    return HC_index, SZ_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e1cd2f-b9e7-450a-90f2-1cb7c34d9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_argparser()\n",
    "#args = parser.parse_args()\n",
    "\n",
    "#args = parser.parse_args(args=['--req_1', '10', '--req_2', '10'])\n",
    "\n",
    "args = parser.parse_args(args=['--path', '/om2/scratch/Fri/jsmentch/dice_scratch/wandb', \n",
    "                              '--oldpath', '/om2/scratch/Fri/jsmentch/dice_scratch/wandb', \n",
    "                              '--fig-path', '/om2/scratch/Fri/jsmentch/dice_scratch/wandb', \n",
    "                              '--p-path', '/om2/scratch/Fri/jsmentch/dice_scratch/wandb', \n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f1f962-0361-4fd3-b31a-f91ff7baf513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID = 4\n",
      "exp = NPT\n",
      "pretraining = None\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# ID = args.script_ID + 3\n",
    "ID = args.script_ID - 1 #? task array id...\n",
    "JobID = args.job_ID #? used for naming files\n",
    "\n",
    "\n",
    "ID = 4\n",
    "print('ID = ' + str(ID))\n",
    "print('exp = ' + args.exp)\n",
    "print('pretraining = ' + args.pre_training)\n",
    "sID = str(ID)\n",
    "currentDT = datetime.datetime.now()\n",
    "d1 = currentDT.strftime(\"%Y-%m-%d%H:%M:%S\")\n",
    "d2 = '_' + str(JobID) + '_ startFold_' + str(args.starting_test_fold) + '_' + str(args.n_test_folds_to_run)\n",
    "\n",
    "Name = args.exp + '_FBIRN_' + args.pre_training + 'DICE_Default'\n",
    "dir = 'run-' + d1 + d2 + Name\n",
    "dir = dir + '-' + str(ID)\n",
    "wdb = 'wandb_new'\n",
    "\n",
    "wpath = os.path.join(os.getcwd(), wdb)\n",
    "path = os.path.join(wpath, dir)\n",
    "args.path = path\n",
    "os.mkdir(path)\n",
    "\n",
    "wdb1 = 'wandb_new'\n",
    "wpath1 = os.path.join(os.getcwd(), wdb1)\n",
    "\n",
    "\n",
    "p = 'UF'\n",
    "dir = 'run-2019-09-1223:36:31' + '-' + str(ID) + 'FPT_ICA_COBRE'\n",
    "p_path = os.path.join(os.getcwd(), p)\n",
    "p_path = os.path.join(p_path, dir) \n",
    "args.p_path = p_path\n",
    "# os.mkdir(fig_path)\n",
    "# hf = h5py.File('../FBIRN_AllData.h5', 'w')\n",
    "tfilename = str(JobID) + 'outputFILENEWONE' + Name + str(ID)\n",
    "\n",
    "output_path = os.path.join(os.getcwd(), 'Output')\n",
    "output_path = os.path.join(output_path, tfilename)\n",
    "# output_text_file = open(output_path, \"w+\")\n",
    "# writer = SummaryWriter('exp-1')\n",
    "ntrials = args.ntrials\n",
    "ngtrials = 10\n",
    "best_auc = 0.\n",
    "best_gain = 0\n",
    "current_gain=0\n",
    "# train_sub_SZ = [15, 25, 50, 75, 142, 125] #142, 132 80 #? i think tr means train not TR ?\n",
    "# train_sub_HC = [15, 25, 50, 75, 134, 125] #134, 124 74 #? so training on 142/134 .. ah\n",
    "\n",
    "# With 16 per sub val, 10 WS working, MILC default\n",
    "if args.exp == 'FPT':\n",
    "    gain = [0.45, 0.05, 0.05, 0.15, 0.85]  # FPT\n",
    "elif args.exp == 'UFPT':\n",
    "    gain = [3, 3, 3, 3, 3, 3]  # UFPT\n",
    "else:\n",
    "    gain = [1, 1, 1, 1, 2.25, 1]  # NPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78139ea1-7e5f-416b-a586-fd1758727bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will do a stratified kfold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f26bf1-318c-42f9-b2d0-bb3fad84b1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cpu\n",
      "device =  cpu\n"
     ]
    }
   ],
   "source": [
    "# sub_per_class_SZ = train_sub_SZ[ID]\n",
    "# sub_per_class_HC = train_sub_HC[ID]\n",
    "current_gain = gain[ID]\n",
    "args.gain = current_gain\n",
    "# sample_x = 100 #? unused ?\n",
    "sample_y = 1\n",
    "subjects = sub_list.shape[0] #78 #311\n",
    "\n",
    "# tc = 160 #? unused ?\n",
    "\n",
    "# samples_per_subject = int(tc / sample_y)\n",
    "samples_per_subject = mmp_data.shape[2]\n",
    "# samples_per_subject = int((tc - sample_y)+1)\n",
    "# ntest_samples_perclass_SZ = 9\n",
    "# ntest_samples_perclass_HC = 8\n",
    "# if ID == 5:\n",
    "#     nval_samples_perclass = 15\n",
    "# else:\n",
    "#     nval_samples_perclass_SZ = 9\n",
    "#     nval_samples_perclass_HC = 8\n",
    "# test_start_index = 0\n",
    "# test_end_index = test_start_index + ntest_samples_perclass_SZ\n",
    "window_shift = 1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cudaID = str(torch.cuda.current_device())\n",
    "    print(torch.cuda.device_count())\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    device2 = torch.device(\"cuda:0\")\n",
    "    # device = torch.device(\"cuda:\" + str(args.cuda_id))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    device2 = device\n",
    "print('device = ', device)\n",
    "print('device = ', device2)\n",
    "\n",
    "# n_good_comp = 53\n",
    "n_regions = 360\n",
    "\n",
    "# with open('../DataandLabels/FBIRN_alldata_new_160.npz', 'rb') as file:\n",
    "#     data = np.load(file)\n",
    "\n",
    "data=mmp_data\n",
    "# data[data != data] = 0 #??\n",
    "\n",
    "for t in range(subjects):\n",
    "    for r in range(n_regions):\n",
    "        data[t, r, :] = stats.zscore(data[t, r, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a1a5624-a8a3-4bd1-96aa-d844ccb284ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41,)\n",
      "(37,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# data = data + 2\n",
    "data = torch.from_numpy(data).float()\n",
    "finalData = np.zeros((subjects, samples_per_subject, n_regions, sample_y))\n",
    "for i in range(subjects):\n",
    "    for j in range(samples_per_subject):\n",
    "        #if j != samples_per_subject-1:\n",
    "        finalData[i, j, :, :] = data[i, :, (j * window_shift):(j * window_shift) + sample_y]\n",
    "        #else:\n",
    "            #finalData[i, j, :, :17] = data[i, :, (j * window_shift):]\n",
    "\n",
    "\n",
    "start_path = '../Atlases2'\n",
    "count = 0;\n",
    "\n",
    "# test_indices_HC = [0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136]\n",
    "# test_indices_SZ = [0, 9, 18, 27, 36, 45, 54, 63, 72, 81, 90, 99, 108, 117, 126, 135, 144, 153]\n",
    "\n",
    "\n",
    "number_of_test_folds_to_run = args.n_test_folds_to_run\n",
    "n_regions_output = n_regions\n",
    "# tc_after_encoder = 155 #? unused?\n",
    "HC_index, SZ_index = find_indices_of_each_class(dx_list)\n",
    "print(HC_index.shape)\n",
    "print(SZ_index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc8abb34-4c16-4fd2-afab-fb8604dd96b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return\n",
    "# total_test_size = ntest_samples_perclass_HC + ntest_samples_perclass_SZ\n",
    "results = torch.zeros(ntrials * number_of_test_folds_to_run, 10)\n",
    "result_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7efd06d4-a7ad-49e9-92ce-5a100e681964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22b08472-35a1-4cba-b650-c5ee3f9131f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sss \u001b[38;5;241m=\u001b[39m StratifiedShuffleSplit(n_splits\u001b[38;5;241m=\u001b[39mntrials, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train_index, val_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sss\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_index\u001b[49m)):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(val_index)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_index' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46d183f1-1f10-47c6-8c06-4ce7c065bbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd969d80-5fe5-495e-a030-bd0d609ff508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [10 12 13 14 15 16 17 20 21 23 24 27 28 29 30 31 32 33 34 35 36 37 38 39\n",
      " 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63\n",
      " 64 65 66 67 68 69 70 71 72 73 74 75 76 77]\n",
      "test [ 0  1  2  3  4  5  6  7  8  9 11 18 19 22 25 26]\n",
      "test Id = 0\n",
      "[ 7 57 51 38 42 11 40 18 25 15 45  0 28]\n",
      "trial =  0\n",
      "torch.Size([49, 250, 360, 1])\n",
      "torch.Size([13, 250, 360, 1])\n",
      "torch.Size([16, 250, 360, 1])\n",
      "torch.Size([49])\n",
      "torch.Size([13])\n",
      "torch.Size([16])\n",
      "obs shape 1\n",
      "lstm init weight\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 117\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPre_Trained/DECENNT/UsingHCP500TP/model.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    111\u001b[0m         args\u001b[38;5;241m.\u001b[39moldpath \u001b[38;5;241m=\u001b[39m wpath1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Pre_Trained/DECENNT/UsingHCP500TP\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 117\u001b[0m complete_model \u001b[38;5;241m=\u001b[39m \u001b[43mcombinedModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlstm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples_per_subject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_gain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_training\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_one\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moldpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moldpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_regions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_regions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice_two\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice_zero\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice_extra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice2\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m complete_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    119\u001b[0m config \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/net/vast-storage.ib.cluster/scratch/scratch/Fri/jsmentch/DICE/src/All_Architecture.py:96\u001b[0m, in \u001b[0;36mcombinedModel.__init__\u001b[0;34m(self, encoder, lstm, samples_per_subject, gain, PT, exp, device_one, oldpath, k, n_regions, device_two, device_zero, device_extra)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgta_embed \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_regions \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_regions, \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupscale \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_regions \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_regions)),\n\u001b[1;32m     91\u001b[0m                                 )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_two)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgta_norm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(nn\u001b[38;5;241m.\u001b[39mBatchNorm1d(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupscale \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_regions \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_regions)), nn\u001b[38;5;241m.\u001b[39mReLU())\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_two)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgta_attend \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m---> 96\u001b[0m     \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_regions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_regions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupscale2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_regions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_regions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     97\u001b[0m                                  nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m     98\u001b[0m                                  \u001b[38;5;66;03m# nn.Dropout(0.2),\u001b[39;00m\n\u001b[1;32m     99\u001b[0m                                  nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupscale2 \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_regions \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_regions), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_two)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# self.embed = nn.Linear(64,round(self.upscale2 * 64))  # .to(self.device_two)\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# self.norm = nn.Sequential(nn.BatchNorm1d(round(self.upscale2 * 64)),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# self.gta_attend_embeddings = nn.Linear(round(self.upscale * self.n_regions * self.attention_embedding), 1).to(self.device_one)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgta_dropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.35\u001b[39m)\n",
      "File \u001b[0;32m/om2/user/jsmentch/anaconda/envs/dice/lib/python3.10/site-packages/torch/nn/modules/linear.py:101\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/om2/user/jsmentch/anaconda/envs/dice/lib/python3.10/site-packages/torch/nn/modules/linear.py:107\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m         fan_in, _ \u001b[38;5;241m=\u001b[39m init\u001b[38;5;241m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n",
      "File \u001b[0;32m/om2/user/jsmentch/anaconda/envs/dice/lib/python3.10/site-packages/torch/nn/init.py:412\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    410\u001b[0m bound \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m) \u001b[38;5;241m*\u001b[39m std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "for test_ID, (trainval_indices, test_indices) in enumerate(skf.split(data, y=dx_list)):\n",
    "    print('train',trainval_indices)\n",
    "    print('test',test_indices)\n",
    "    # test_ID = test_ID + args.starting_test_fold\n",
    "#     if test_ID == 17:\n",
    "#         ntest_samples_perclass_SZ = 7\n",
    "#         ntest_samples_perclass_HC = 14#15#14\n",
    "\n",
    "#         sub_per_class_SZ = 144#134\n",
    "#         sub_per_class_HC = 128#118\n",
    "\n",
    "    print('test Id =', test_ID)\n",
    "\n",
    "    # test_start_index_SZ = test_indices_SZ[test_ID]\n",
    "    # test_start_index_HC = test_indices_HC[test_ID]\n",
    "    # test_end_index_SZ = test_start_index_SZ + ntest_samples_perclass_SZ\n",
    "    # test_end_index_HC = test_start_index_HC + ntest_samples_perclass_HC\n",
    "    # total_HC_index_tr_val = torch.cat([HC_index[:test_start_index_HC], HC_index[test_end_index_HC:]])\n",
    "    # total_SZ_index_tr_val = torch.cat([SZ_index[:test_start_index_SZ], SZ_index[test_end_index_SZ:]])\n",
    "\n",
    "    # HC_index_test = HC_index[test_start_index_HC:test_end_index_HC]\n",
    "    # SZ_index_test = SZ_index[test_start_index_SZ:test_end_index_SZ]\n",
    "\n",
    "    # total_HC_index_tr = total_HC_index_tr_val[:(total_HC_index_tr_val.shape[0] - nval_samples_perclass_HC)]\n",
    "    # total_SZ_index_tr = total_SZ_index_tr_val[:(total_SZ_index_tr_val.shape[0] - nval_samples_perclass_SZ)]\n",
    "\n",
    "    # HC_index_val = total_HC_index_tr_val[(total_HC_index_tr_val.shape[0] - nval_samples_perclass_HC):]\n",
    "    # SZ_index_val = total_SZ_index_tr_val[(total_SZ_index_tr_val.shape[0] - nval_samples_perclass_SZ):]\n",
    "\n",
    "    auc_arr = torch.zeros(ngtrials, 1)\n",
    "    avg_auc = 0.\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=ntrials, test_size=0.2, random_state=0)\n",
    "    for trial, (train_indices, val_indices) in enumerate(sss.split(X=data[trainval_indices], y=dx_list[trainval_indices] )):\n",
    "\n",
    "        print(val_indices)\n",
    "        print ('trial = ', trial)\n",
    "\n",
    "        g_trial=1\n",
    "        output_text_file = open(output_path, \"a+\")\n",
    "        output_text_file.write(\"Test fold number = %d Trial = %d\\r\\n\" % (test_ID,trial))\n",
    "        output_text_file.close()\n",
    "        # Get subject_per_class number of random values\n",
    "        # HC_random = torch.randperm(total_HC_index_tr.shape[0])\n",
    "        # SZ_random = torch.randperm(total_SZ_index_tr.shape[0])\n",
    "        # HC_random = HC_random[:sub_per_class_HC]\n",
    "        # SZ_random = SZ_random[:sub_per_class_SZ]\n",
    "        # HC_random = torch.randint(high=len(total_HC_index_tr), size=(sub_per_class,))\n",
    "        # SZ_random = torch.randint(high=len(total_SZ_index_tr), size=(sub_per_class,))\n",
    "        #\n",
    "\n",
    "        # Choose the subject_per_class indices from HC_index_val and SZ_index_val using random numbers\n",
    "\n",
    "        # HC_index_tr = total_HC_index_tr[HC_random]\n",
    "        # SZ_index_tr = total_SZ_index_tr[SZ_random]\n",
    "\n",
    "#         tr_index = torch.cat((HC_index_tr, SZ_index_tr))\n",
    "#         val_index = torch.cat((HC_index_val, SZ_index_val))\n",
    "#         test_index = torch.cat((HC_index_test, SZ_index_test))\n",
    "\n",
    "#         tr_index = tr_index.view(tr_index.size(0))\n",
    "#         val_index = val_index.view(val_index.size(0))\n",
    "#         test_index = test_index.view(test_index.size(0))\n",
    "        \n",
    "        tr_index = torch.from_numpy(train_indices)\n",
    "        val_index = torch.from_numpy(val_indices)\n",
    "        test_index = torch.from_numpy(test_indices)\n",
    "\n",
    "        \n",
    "        tr_eps = torch.from_numpy(finalData[tr_index.long(), :, :, :])\n",
    "        val_eps = torch.from_numpy(finalData[val_index.long(), :, :, :])\n",
    "        test_eps = torch.from_numpy(finalData[test_index.long(), :, :, :])\n",
    "\n",
    "        tr_labels = torch.from_numpy(dx_list[tr_index.long()])\n",
    "        val_labels = torch.from_numpy(dx_list[val_index.long()])\n",
    "        test_labels = torch.from_numpy(dx_list[test_index.long()])\n",
    "\n",
    "        tr_labels = tr_labels.to(device)\n",
    "        val_labels = val_labels.to(device)\n",
    "        test_labels = test_labels.to(device)\n",
    "\n",
    "\n",
    "        tr_eps = tr_eps.to(device)\n",
    "        # val_eps = val_eps.to(device)\n",
    "        test_eps = test_eps.to(device)\n",
    "\n",
    "        print(tr_eps.shape)\n",
    "        print(val_eps.shape)\n",
    "        print(test_eps.shape)\n",
    "\n",
    "        print(tr_labels.shape)\n",
    "        print(val_labels.shape)\n",
    "        print(test_labels.shape)\n",
    "\n",
    "\n",
    "        observation_shape = finalData.shape\n",
    "        L=\"\"\n",
    "        lmax=\"\"\n",
    "        number_of_graph_channels = 1\n",
    "        if args.model_type == \"graph_the_works\":\n",
    "            print('obs shape',observation_shape[3])\n",
    "            encoder = NatureCNN(observation_shape[3], args)\n",
    "\n",
    "            encoder.to(device)\n",
    "            lstm_model = subjLSTM(device, sample_y, args.lstm_size, num_layers=args.lstm_layers,\n",
    "                                  freeze_embeddings=True, gain=current_gain,bidrection=True)\n",
    "            dir = \"\"\n",
    "            if args.pre_training == \"DECENNT\":\n",
    "                dir = 'Pre_Trained/DECENNT/UsingHCP500TP/model.pt'\n",
    "                args.oldpath = wpath1 + '/Pre_Trained/DECENNT/UsingHCP500TP'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        complete_model = combinedModel(encoder,lstm_model, samples_per_subject, gain=current_gain, PT=args.pre_training, exp=args.exp, device_one=device, oldpath=args.oldpath,n_regions=n_regions,device_two=device2,device_zero=device2,device_extra=device2 )\n",
    "        complete_model.to(device)\n",
    "        config = {}\n",
    "        config.update(vars(args))\n",
    "        # print(\"trainershape\", os.path.join(wandb.run.dir, config['env_name'] + '.pt'))\n",
    "        config['obs_space'] = observation_shape  # weird hack\n",
    "        if args.method == \"graph_the_works\":\n",
    "            trainer = the_works_trainer(complete_model, config, device=device2, device_encoder=device,\n",
    "                                        tr_labels=tr_labels,\n",
    "                                  val_labels=val_labels, test_labels=test_labels, trial=str(trial),\n",
    "                                        crossv=str(test_ID),gtrial=str(g_trial))\n",
    "\n",
    "        else:\n",
    "            assert False, \"method {} has no trainer\".format(args.method)\n",
    "        results[result_counter][0], results[result_counter][1], results[result_counter][2], \\\n",
    "        results[result_counter][3],results[result_counter][4],\\\n",
    "        results[result_counter][5], _ = trainer.train(tr_eps, val_eps, test_eps)\n",
    "\n",
    "        result_counter = result_counter + 1\n",
    "        tresult_csv = os.path.join(args.path, 'test_results' + sID + '.csv')\n",
    "        np.savetxt(tresult_csv, results.numpy(), delimiter=\",\")\n",
    "\n",
    "np_results = results.numpy()\n",
    "auc = np_results[:,1]\n",
    "acc = np_results[:, 0]\n",
    "print('mean test auc = ', np.mean(acc[:]))\n",
    "print('mean test acc = ', np.mean(auc[:]))\n",
    "\n",
    "tresult_csv = os.path.join(args.path, 'test_results' + sID + '.csv')\n",
    "np.savetxt(tresult_csv, np_results, delimiter=\",\")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print('total time = ', elapsed);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "688284f0-c65f-420a-8b0d-e851dd611455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 250, 360, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_eps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "601c7857-6539-454d-a0ee-b522bc895356",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_labels = dx_list[tr_index.long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c68e4-c12f-4683-9ed3-8a1a626fec78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
