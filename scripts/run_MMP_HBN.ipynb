{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bffc261-4deb-4af2-93c2-f9a73a7c770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available True\n",
      "data shape = (78, 360, 250)\n",
      "ID = 4\n",
      "exp = NPT\n",
      "pretraining = None\n",
      "1\n",
      "device =  cuda:0\n",
      "device =  cuda:0\n",
      "HC_index.shape (41,)\n",
      "SZ_index.shape (37,)\n",
      "args = Namespace(pre_training='None', fMRI_twoD=False, deep=False, path='/net/vast-storage.ib.cluster/scratch/scratch/Fri/jsmentch/DICE/scripts/wandb_new/run-2023-01-0616:32:22_1_ startFold_0_1NPT_FBIRN_NoneDICE_Default-4', oldpath='/om2/scratch/Fri/jsmentch/dice_scratch/wandb', fig_path='/om2/scratch/Fri/jsmentch/dice_scratch/wandb', p_path='/net/vast-storage.ib.cluster/scratch/scratch/Fri/jsmentch/DICE/scripts/UF/run-2019-09-1223:36:31-4FPT_ICA_COBRE', exp='NPT', gain=2.25, temperature=0.25, script_ID=1, n_test_folds_to_run=1, starting_test_fold=0, teststart_ID=1, job_ID=1, ntrials=10, sample_number=0, env_name='MontezumaRevengeNoFrameskip-v4', num_frame_stack=1, no_downsample=True, pretraining_steps=100000, probe_steps=50000, num_processes=8, method='graph_the_works', linear=True, use_multiple_predictors=False, lr=0.0002, batch_size=5, epochs=300, cuda_id=1, seed=42, encoder_type='Nature', model_type='graph_the_works', feature_size=2, fully_connected=False, feature_size_pre_training=32, fMRI_feature_size=1024, patience=15, entropy_threshold=0.6, color=False, end_with_relu=False, wandb_proj='curl-atari-neurips-scratch', num_rew_evals=10, checkpoint_index=-1, naff_fc_size=2048, pred_offset=1, sequence_length=100, steps_start=0, steps_end=99, steps_step=4, gru_size=256, lstm_size=100, lstm_size_within_window=8, fMRI_lstm_size=100, gru_layers=1, lstm_layers=1, collect_mode='random_agent', beta=1.0, weights_path='None', train_encoder=True, probe_lr=3e-06, probe_collect_mode='random_agent', num_runs=1)\n",
      "test Id = 0\n",
      "trial =  0\n",
      "tr_eps torch.Size([49, 250, 360, 1]) torch.float32\n",
      "val_eps torch.Size([13, 250, 360, 1]) torch.float32\n",
      "test_eps torch.Size([16, 250, 360, 1]) torch.float32\n",
      "tr_labels torch.Size([49]) torch.int64\n",
      "val_labels torch.Size([13]) torch.int64\n",
      "test_labels torch.Size([16]) torch.int64\n",
      "obs shape 1\n",
      "lstm init weight\n",
      "lr =  0.0002\n",
      "2.25\n",
      "initNPT\n",
      "Train Test fold: 0, Trial: 0, Epoch: 0, Loss: 8.22424840927124, Accuracy: 0.44897958636283875, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 0, Loss: 7.148236115773519, Accuracy: 0.46153849363327026, roc: 0.6547619047619049, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 1, Loss: 6.4498766422271725, Accuracy: 0.6326530575752258, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 1, Loss: 5.860521952311198, Accuracy: 0.46153849363327026, roc: 0.4761904761904763, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 2, Loss: 5.286071157455444, Accuracy: 0.6326530575752258, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 2, Loss: 4.902311007181804, Accuracy: 0.46153849363327026, roc: 0.2857142857142857, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 3, Loss: 4.428629779815674, Accuracy: 0.6326530575752258, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 3, Loss: 4.279886245727539, Accuracy: 0.46153849363327026, roc: 0.38095238095238093, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 4, Loss: 3.770507025718689, Accuracy: 0.6734693646430969, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 4, Loss: 3.8290682633717856, Accuracy: 0.46153849363327026, roc: 0.35714285714285715, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 5, Loss: 3.247826075553894, Accuracy: 0.8775510191917419, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 5, Loss: 3.442023197809855, Accuracy: 0.46153849363327026, roc: 0.7380952380952381, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 6, Loss: 2.7575304746627807, Accuracy: 0.8367346525192261, roc: 0.0, prec: 0.0, recall:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/jsmentch/anaconda/envs/dice/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Test fold: 0, Trial: 0, Epoch: 6, Loss: 3.349881728490194, Accuracy: 0.5384615659713745, roc: 0.35714285714285715, prec: 0.0, recall:0.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 7, Loss: 2.390977454185486, Accuracy: 0.918367326259613, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 7, Loss: 3.949028571446737, Accuracy: 0.46153849363327026, roc: 0.2857142857142857, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 8, Loss: 2.016491961479187, Accuracy: 0.9795918464660645, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 8, Loss: 2.8319739500681558, Accuracy: 0.46153849363327026, roc: 0.7142857142857143, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 9, Loss: 1.8649410724639892, Accuracy: 0.9591836333274841, roc: 0.0, prec: 0.0, recall:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/jsmentch/anaconda/envs/dice/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Test fold: 0, Trial: 0, Epoch: 9, Loss: 2.3102023601531982, Accuracy: 0.5384615659713745, roc: 0.5, prec: 0.0, recall:0.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 10, Loss: 1.7851476073265076, Accuracy: 0.9387754797935486, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 10, Loss: 3.6828834215799966, Accuracy: 0.46153849363327026, roc: 0.7142857142857141, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 11, Loss: 1.460642445087433, Accuracy: 0.9795918464660645, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 11, Loss: 2.322020332018534, Accuracy: 0.46153849363327026, roc: 0.3571428571428572, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 12, Loss: 1.2464608907699586, Accuracy: 0.9795918464660645, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 12, Loss: 2.183726708094279, Accuracy: 0.46153849363327026, roc: 0.4523809523809524, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 13, Loss: 1.0598346769809723, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 13, Loss: 2.66326634089152, Accuracy: 0.46153849363327026, roc: 0.5238095238095238, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 14, Loss: 1.0751410484313966, Accuracy: 0.9591836333274841, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 14, Loss: 3.2902088165283203, Accuracy: 0.46153849363327026, roc: 0.5952380952380953, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 15, Loss: 0.8989289164543152, Accuracy: 0.9591836333274841, roc: 0.0, prec: 0.0, recall:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/jsmentch/anaconda/envs/dice/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Test fold: 0, Trial: 0, Epoch: 15, Loss: 3.410492698351542, Accuracy: 0.5384615659713745, roc: 0.7142857142857144, prec: 0.0, recall:0.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 16, Loss: 1.0262608349323272, Accuracy: 0.918367326259613, roc: 0.0, prec: 0.0, recall:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/jsmentch/anaconda/envs/dice/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Test fold: 0, Trial: 0, Epoch: 16, Loss: 7.96312157313029, Accuracy: 0.5384615659713745, roc: 0.6904761904761904, prec: 0.0, recall:0.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 17, Loss: 0.7609202444553376, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 17, Loss: 1.664725661277771, Accuracy: 0.692307710647583, roc: 0.6190476190476191, prec: 0.625, recall:0.8333333333333334\n",
      "Train Test fold: 0, Trial: 0, Epoch: 18, Loss: 0.7269507646560669, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 18, Loss: 2.132479429244995, Accuracy: 0.5384615659713745, roc: 0.5952380952380952, prec: 0.5, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 19, Loss: 0.666875159740448, Accuracy: 0.9795918464660645, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 19, Loss: 3.1970481077829995, Accuracy: 0.46153849363327026, roc: 0.5714285714285715, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 20, Loss: 0.5854241073131561, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 20, Loss: 2.953991174697876, Accuracy: 0.46153849363327026, roc: 0.6428571428571429, prec: 0.4615384615384615, recall:1.0\n",
      "Train Test fold: 0, Trial: 0, Epoch: 21, Loss: 0.539324015378952, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 21, Loss: 1.8638029893239338, Accuracy: 0.46153849363327026, roc: 0.6904761904761904, prec: 0.45454545454545453, recall:0.8333333333333334\n",
      "Train Test fold: 0, Trial: 0, Epoch: 22, Loss: 0.4984607994556427, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 22, Loss: 2.3079076608022056, Accuracy: 0.5384615659713745, roc: 0.6666666666666666, prec: 0.5, recall:1.0\n",
      "EarlyStopping for model counter: 5 out of 15\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Train Test fold: 0, Trial: 0, Epoch: 23, Loss: 0.4708880841732025, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 23, Loss: 3.751572926839193, Accuracy: 0.46153849363327026, roc: 0.5952380952380952, prec: 0.4615384615384615, recall:1.0\n",
      "EarlyStopping for model counter: 6 out of 15\n",
      "Train Test fold: 0, Trial: 0, Epoch: 24, Loss: 0.4657228887081146, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 24, Loss: 2.8292242288589478, Accuracy: 0.46153849363327026, roc: 0.5476190476190477, prec: 0.4615384615384615, recall:1.0\n",
      "EarlyStopping for model counter: 7 out of 15\n",
      "Train Test fold: 0, Trial: 0, Epoch: 25, Loss: 0.4261345148086548, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 25, Loss: 2.565619468688965, Accuracy: 0.46153849363327026, roc: 0.5714285714285714, prec: 0.45454545454545453, recall:0.8333333333333334\n",
      "EarlyStopping for model counter: 8 out of 15\n",
      "Train Test fold: 0, Trial: 0, Epoch: 26, Loss: 0.41029076278209686, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 26, Loss: 2.309534231821696, Accuracy: 0.46153849363327026, roc: 0.5476190476190477, prec: 0.45454545454545453, recall:0.8333333333333334\n",
      "EarlyStopping for model counter: 9 out of 15\n",
      "Train Test fold: 0, Trial: 0, Epoch: 27, Loss: 0.39690310060977935, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 27, Loss: 2.347823897997538, Accuracy: 0.46153849363327026, roc: 0.5476190476190477, prec: 0.45454545454545453, recall:0.8333333333333334\n",
      "EarlyStopping for model counter: 10 out of 15\n",
      "Epoch 00028: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Train Test fold: 0, Trial: 0, Epoch: 28, Loss: 0.38493432700634, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 28, Loss: 2.160669445991516, Accuracy: 0.46153849363327026, roc: 0.5476190476190477, prec: 0.45454545454545453, recall:0.8333333333333334\n",
      "EarlyStopping for model counter: 11 out of 15\n",
      "Train Test fold: 0, Trial: 0, Epoch: 29, Loss: 0.38507468104362486, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 29, Loss: 2.9025007088979087, Accuracy: 0.46153849363327026, roc: 0.5476190476190477, prec: 0.4615384615384615, recall:1.0\n",
      "EarlyStopping for model counter: 12 out of 15\n",
      "Train Test fold: 0, Trial: 0, Epoch: 30, Loss: 0.3708409756422043, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 30, Loss: 3.089031378428141, Accuracy: 0.38461539149284363, roc: 0.5714285714285714, prec: 0.4166666666666667, recall:0.8333333333333334\n",
      "EarlyStopping for model counter: 13 out of 15\n",
      "Train Test fold: 0, Trial: 0, Epoch: 31, Loss: 0.36280387043952944, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 31, Loss: 2.5125245253245034, Accuracy: 0.46153849363327026, roc: 0.5714285714285714, prec: 0.45454545454545453, recall:0.8333333333333334\n",
      "EarlyStopping for model counter: 14 out of 15\n",
      "Train Test fold: 0, Trial: 0, Epoch: 32, Loss: 0.35637988448143004, Accuracy: 1.0, roc: 0.0, prec: 0.0, recall:0.0\n",
      "Eval Test fold: 0, Trial: 0, Epoch: 32, Loss: 2.3573896090189614, Accuracy: 0.46153849363327026, roc: 0.5714285714285714, prec: 0.45454545454545453, recall:0.8333333333333334\n",
      "EarlyStopping for model counter: 15 out of 15\n",
      "model has stopped\n",
      "Epoch 00033: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Best model was 17\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Test Test fold: 0, Trial: 0, Epoch: 0, Loss: 0.3440337469801307, Accuracy: 0.875, roc: 0.9206349206349207, prec: 0.7777777777777778, recall:1.0\n",
      "trial =  1\n",
      "tr_eps torch.Size([49, 250, 360, 1]) torch.float32\n",
      "val_eps torch.Size([13, 250, 360, 1]) torch.float32\n",
      "test_eps torch.Size([16, 250, 360, 1]) torch.float32\n",
      "tr_labels torch.Size([49]) torch.int64\n",
      "val_labels torch.Size([13]) torch.int64\n",
      "test_labels torch.Size([16]) torch.int64\n",
      "obs shape 1\n",
      "lstm init weight\n",
      "lr =  0.0002\n",
      "2.25\n",
      "initNPT\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 359\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m has no trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(args\u001b[38;5;241m.\u001b[39mmethod)\n\u001b[1;32m    357\u001b[0m results[result_counter][\u001b[38;5;241m0\u001b[39m], results[result_counter][\u001b[38;5;241m1\u001b[39m], results[result_counter][\u001b[38;5;241m2\u001b[39m], \\\n\u001b[1;32m    358\u001b[0m results[result_counter][\u001b[38;5;241m3\u001b[39m],results[result_counter][\u001b[38;5;241m4\u001b[39m],\\\n\u001b[0;32m--> 359\u001b[0m results[result_counter][\u001b[38;5;241m5\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_eps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_eps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_eps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m#ipdb>  print(batch_sizes.dtype)\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m#torch.int64\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m#ipdb>  print(input.dtype)\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m#torch.float64\u001b[39;00m\n\u001b[1;32m    366\u001b[0m result_counter \u001b[38;5;241m=\u001b[39m result_counter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/net/vast-storage.ib.cluster/scratch/scratch/Fri/jsmentch/DICE/src/graph_the_works_fMRI.py:671\u001b[0m, in \u001b[0;36mthe_works_trainer.train\u001b[0;34m(self, tr_eps, val_eps, tst_eps)\u001b[0m\n\u001b[1;32m    664\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;66;03m# tr_eps = tr_eps.permute(0, 2, 1, 3).contiguous().reshape(292 * 100, 160, 1)\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# packed = tn.pack_sequence(tr_eps, enforce_sorted=False)\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m# return\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#t = time.time()\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m# print('e',e)\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;66;03m# print('tr_eps',tr_eps.shape)\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_eps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m#print(\"train time\", time.time()-t)\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/net/vast-storage.ib.cluster/scratch/scratch/Fri/jsmentch/DICE/src/graph_the_works_fMRI.py:370\u001b[0m, in \u001b[0;36mthe_works_trainer.do_one_epoch\u001b[0;34m(self, epoch, episodes, mode)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# self.scheduler.step()\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# t = time.time()\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# loss = loss + loss2\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# if mode == \"test\":\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m#     epoch += torch.sqrt(loss.detach().item())\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# epoch_loss2 += (loss2.detach().item())\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# epoch_loss3 += (loss3.detach().item())\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# epoch_accuracy += accuracy.detach().item()\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# epoch_accuracy2 += accuracy2#.detach().item()\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_logits \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import deque\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "from scipy import stats\n",
    "import torch.nn as nn\n",
    "from src.utils import get_argparser\n",
    "from src.encoders_ICA import NatureCNN\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from src.lstm_attn import subjLSTM\n",
    "from src.All_Architecture import combinedModel\n",
    "\n",
    "# import torchvision.models.resnet_conv1D as models\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "from src.graph_the_works_fMRI import the_works_trainer\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import h5py\n",
    "import math\n",
    "from copy import  copy\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import torch.nn.utils.rnn as tn\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# try to get a  QUADRORTX6000; 1080 doesn't have enough memory. a6000 not compatible.\n",
    "# or just use A100\n",
    "\n",
    "def find_indices_of_each_class(dx_list):\n",
    "    HC_index = (dx_list == 0).nonzero()[0]\n",
    "    SZ_index = (dx_list == 1).nonzero()[0] #SZ will be ASC for our purposes\n",
    "    return HC_index, SZ_index\n",
    "\n",
    "print('torch.cuda.is_available',torch.cuda.is_available())\n",
    "torch.cuda.init()\n",
    "\n",
    "#load my data\n",
    "with np.load('/om2/scratch/Fri/jsmentch/nat_img/sourcedata/data/HBN/brain/clean/for_dice/movieTP.npz', 'rb') as file:\n",
    "    sub_list=file['arr_0']\n",
    "    ses_list=file['arr_1']\n",
    "    dx_list=file['arr_2']\n",
    "    mmp_data=file['arr_3']\n",
    "\n",
    "#subject, parcels, timepoints\n",
    "print('data shape =',mmp_data.shape)\n",
    "\n",
    "# dx_list.sum()\n",
    "# dx_list.shape\n",
    "\n",
    "# #37 with ASC; 41 NT; 78 total\n",
    "\n",
    "parser = get_argparser()\n",
    "#args = parser.parse_args()\n",
    "\n",
    "#args = parser.parse_args(args=['--req_1', '10', '--req_2', '10'])\n",
    "\n",
    "args = parser.parse_args(args=['--path', '/om2/scratch/Fri/jsmentch/dice_scratch/wandb', \n",
    "                              '--oldpath', '/om2/scratch/Fri/jsmentch/dice_scratch/wandb', \n",
    "                              '--fig-path', '/om2/scratch/Fri/jsmentch/dice_scratch/wandb', \n",
    "                              '--p-path', '/om2/scratch/Fri/jsmentch/dice_scratch/wandb'])\n",
    "                              #'--lstm_size', '360'])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ID = args.script_ID + 3\n",
    "# ID = args.script_ID - 1 #? task array id...\n",
    "JobID = args.job_ID #? used for naming files?, it is set to 1\n",
    "\n",
    "\n",
    "ID = 4 #? this seems to set which \"gain\" we use?\n",
    "print('ID = ' + str(ID))\n",
    "print('exp = ' + args.exp)\n",
    "print('pretraining = ' + args.pre_training)\n",
    "sID = str(ID)\n",
    "currentDT = datetime.datetime.now()\n",
    "d1 = currentDT.strftime(\"%Y-%m-%d%H:%M:%S\")\n",
    "d2 = '_' + str(JobID) + '_ startFold_' + str(args.starting_test_fold) + '_' + str(args.n_test_folds_to_run)\n",
    "\n",
    "Name = args.exp + '_FBIRN_' + args.pre_training + 'DICE_Default'\n",
    "dir = 'run-' + d1 + d2 + Name\n",
    "dir = dir + '-' + str(ID)\n",
    "wdb = 'wandb_new'\n",
    "\n",
    "wpath = os.path.join(os.getcwd(), wdb)\n",
    "path = os.path.join(wpath, dir)\n",
    "args.path = path\n",
    "os.mkdir(path)\n",
    "\n",
    "wdb1 = 'wandb_new'\n",
    "wpath1 = os.path.join(os.getcwd(), wdb1)\n",
    "\n",
    "\n",
    "p = 'UF'\n",
    "dir = 'run-2019-09-1223:36:31' + '-' + str(ID) + 'FPT_ICA_COBRE'\n",
    "p_path = os.path.join(os.getcwd(), p)\n",
    "p_path = os.path.join(p_path, dir) \n",
    "args.p_path = p_path\n",
    "# os.mkdir(fig_path)\n",
    "# hf = h5py.File('../FBIRN_AllData.h5', 'w')\n",
    "tfilename = str(JobID) + 'outputFILENEWONE' + Name + str(ID)\n",
    "\n",
    "output_path = os.path.join(os.getcwd(), 'Output')\n",
    "output_path = os.path.join(output_path, tfilename)\n",
    "# output_text_file = open(output_path, \"w+\")\n",
    "# writer = SummaryWriter('exp-1')\n",
    "ntrials = args.ntrials\n",
    "# ngtrials = 10 #? seems unused?\n",
    "# best_auc = 0. #? seems unused?\n",
    "# best_gain = 0 #? seems unused?\n",
    "current_gain=0\n",
    "# train_sub_SZ = [15, 25, 50, 75, 142, 125] #142, 132 80 #? i think tr means train not TR ?\n",
    "# train_sub_HC = [15, 25, 50, 75, 134, 125] #134, 124 74 #? so training on 142/134 .. ah\n",
    "\n",
    "# With 16 per sub val, 10 WS working, MILC default\n",
    "if args.exp == 'FPT':\n",
    "    gain = [0.45, 0.05, 0.05, 0.15, 0.85]  # FPT\n",
    "elif args.exp == 'UFPT':\n",
    "    gain = [3, 3, 3, 3, 3, 3]  # UFPT\n",
    "else:\n",
    "    gain = [1, 1, 1, 1, 2.25, 1]  # NPT\n",
    "\n",
    "#we will do a stratified kfold split\n",
    "# sub_per_class_SZ = train_sub_SZ[ID]\n",
    "# sub_per_class_HC = train_sub_HC[ID]\n",
    "current_gain = gain[ID]\n",
    "args.gain = current_gain\n",
    "# sample_x = 100 #? unused ?\n",
    "sample_y = 1 #? how many time points to use?\n",
    "subjects = sub_list.shape[0] #78 #311\n",
    "\n",
    "# tc = 160 #? unused ?\n",
    "\n",
    "# samples_per_subject = int(tc / sample_y)\n",
    "samples_per_subject = mmp_data.shape[2]\n",
    "# samples_per_subject = int((tc - sample_y)+1)\n",
    "# ntest_samples_perclass_SZ = 9\n",
    "# ntest_samples_perclass_HC = 8\n",
    "# if ID == 5:\n",
    "#     nval_samples_perclass = 15\n",
    "# else:\n",
    "#     nval_samples_perclass_SZ = 9\n",
    "#     nval_samples_perclass_HC = 8\n",
    "# test_start_index = 0\n",
    "# test_end_index = test_start_index + ntest_samples_perclass_SZ\n",
    "window_shift = 1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cudaID = str(torch.cuda.current_device())\n",
    "    print(torch.cuda.device_count())\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    device2 = torch.device(\"cuda:0\")\n",
    "    # device = torch.device(\"cuda:\" + str(args.cuda_id))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    device2 = device\n",
    "print('device = ', device)\n",
    "print('device = ', device2)\n",
    "\n",
    "# n_good_comp = 53\n",
    "n_regions = 360\n",
    "\n",
    "# with open('../DataandLabels/FBIRN_alldata_new_160.npz', 'rb') as file:\n",
    "#     data = np.load(file)\n",
    "\n",
    "data=mmp_data\n",
    "# data[data != data] = 0 #??\n",
    "\n",
    "for t in range(subjects):\n",
    "    for r in range(n_regions):\n",
    "        data[t, r, :] = stats.zscore(data[t, r, :])\n",
    "\n",
    "data=np.nan_to_num(data) #get rid of NaNs because for some reason there are 250 nans?\n",
    "\n",
    "# data = data + 2\n",
    "data = torch.from_numpy(data).float()\n",
    "finalData = np.zeros((subjects, samples_per_subject, n_regions, sample_y))\n",
    "for i in range(subjects):#? I think it is just reshaping and not doing any shifting?\n",
    "    for j in range(samples_per_subject):\n",
    "        #if j != samples_per_subject-1:\n",
    "        finalData[i, j, :, :] = data[i, :, (j * window_shift):(j * window_shift) + sample_y]\n",
    "        #else:\n",
    "            #finalData[i, j, :, :17] = data[i, :, (j * window_shift):]\n",
    "\n",
    "\n",
    "start_path = '../Atlases2'\n",
    "# count = 0; #? unused?\n",
    "\n",
    "# test_indices_HC = [0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136]\n",
    "# test_indices_SZ = [0, 9, 18, 27, 36, 45, 54, 63, 72, 81, 90, 99, 108, 117, 126, 135, 144, 153]\n",
    "\n",
    "\n",
    "number_of_test_folds_to_run = args.n_test_folds_to_run\n",
    "n_regions_output = n_regions\n",
    "# tc_after_encoder = 155 #? unused?\n",
    "HC_index, SZ_index = find_indices_of_each_class(dx_list)\n",
    "print('HC_index.shape',HC_index.shape)\n",
    "print('SZ_index.shape',SZ_index.shape)\n",
    "\n",
    "\n",
    "# return\n",
    "# total_test_size = ntest_samples_perclass_HC + ntest_samples_perclass_SZ\n",
    "results = torch.zeros(ntrials * number_of_test_folds_to_run, 10)\n",
    "result_counter = 0\n",
    "\n",
    "print('args =',args)\n",
    "\n",
    "#%debug\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for test_ID, (trainval_indices, test_indices) in enumerate(skf.split(data, y=dx_list)):\n",
    "    # print('train',trainval_indices)\n",
    "    # print('test',test_indices)\n",
    "    # test_ID = test_ID + args.starting_test_fold\n",
    "#     if test_ID == 17:\n",
    "#         ntest_samples_perclass_SZ = 7\n",
    "#         ntest_samples_perclass_HC = 14#15#14\n",
    "\n",
    "#         sub_per_class_SZ = 144#134\n",
    "#         sub_per_class_HC = 128#118\n",
    "\n",
    "    print('test Id =', test_ID)\n",
    "\n",
    "    # test_start_index_SZ = test_indices_SZ[test_ID]\n",
    "    # test_start_index_HC = test_indices_HC[test_ID]\n",
    "    # test_end_index_SZ = test_start_index_SZ + ntest_samples_perclass_SZ\n",
    "    # test_end_index_HC = test_start_index_HC + ntest_samples_perclass_HC\n",
    "    # total_HC_index_tr_val = torch.cat([HC_index[:test_start_index_HC], HC_index[test_end_index_HC:]])\n",
    "    # total_SZ_index_tr_val = torch.cat([SZ_index[:test_start_index_SZ], SZ_index[test_end_index_SZ:]])\n",
    "\n",
    "    # HC_index_test = HC_index[test_start_index_HC:test_end_index_HC]\n",
    "    # SZ_index_test = SZ_index[test_start_index_SZ:test_end_index_SZ]\n",
    "\n",
    "    # total_HC_index_tr = total_HC_index_tr_val[:(total_HC_index_tr_val.shape[0] - nval_samples_perclass_HC)]\n",
    "    # total_SZ_index_tr = total_SZ_index_tr_val[:(total_SZ_index_tr_val.shape[0] - nval_samples_perclass_SZ)]\n",
    "\n",
    "    # HC_index_val = total_HC_index_tr_val[(total_HC_index_tr_val.shape[0] - nval_samples_perclass_HC):]\n",
    "    # SZ_index_val = total_SZ_index_tr_val[(total_SZ_index_tr_val.shape[0] - nval_samples_perclass_SZ):]\n",
    "\n",
    "    #auc_arr = torch.zeros(ngtrials, 1) #? seems unused?\n",
    "    #avg_auc = 0. #? seems unused?\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=ntrials, test_size=0.2, random_state=0)\n",
    "    for trial, (train_indices, val_indices) in enumerate(sss.split(X=data[trainval_indices], y=dx_list[trainval_indices] )):\n",
    "\n",
    "        # print(val_indices)\n",
    "        print ('trial = ', trial)\n",
    "\n",
    "        g_trial=1\n",
    "        output_text_file = open(output_path, \"a+\")\n",
    "        output_text_file.write(\"Test fold number = %d Trial = %d\\r\\n\" % (test_ID,trial))\n",
    "        output_text_file.close()\n",
    "        # Get subject_per_class number of random values\n",
    "        # HC_random = torch.randperm(total_HC_index_tr.shape[0])\n",
    "        # SZ_random = torch.randperm(total_SZ_index_tr.shape[0])\n",
    "        # HC_random = HC_random[:sub_per_class_HC]\n",
    "        # SZ_random = SZ_random[:sub_per_class_SZ]\n",
    "        # HC_random = torch.randint(high=len(total_HC_index_tr), size=(sub_per_class,))\n",
    "        # SZ_random = torch.randint(high=len(total_SZ_index_tr), size=(sub_per_class,))\n",
    "        #\n",
    "\n",
    "        # Choose the subject_per_class indices from HC_index_val and SZ_index_val using random numbers\n",
    "\n",
    "        # HC_index_tr = total_HC_index_tr[HC_random]\n",
    "        # SZ_index_tr = total_SZ_index_tr[SZ_random]\n",
    "\n",
    "#         tr_index = torch.cat((HC_index_tr, SZ_index_tr))\n",
    "#         val_index = torch.cat((HC_index_val, SZ_index_val))\n",
    "#         test_index = torch.cat((HC_index_test, SZ_index_test))\n",
    "\n",
    "#         tr_index = tr_index.view(tr_index.size(0))\n",
    "#         val_index = val_index.view(val_index.size(0))\n",
    "#         test_index = test_index.view(test_index.size(0))\n",
    "        \n",
    "        tr_index = torch.tensor(train_indices)\n",
    "        val_index = torch.tensor(val_indices)\n",
    "        test_index = torch.tensor(test_indices)\n",
    "\n",
    "        \n",
    "        tr_eps = torch.tensor(finalData[tr_index.long(), :, :, :],dtype=torch.float32)\n",
    "        val_eps = torch.tensor(finalData[val_index.long(), :, :, :],dtype=torch.float32)\n",
    "        test_eps = torch.tensor(finalData[test_index.long(), :, :, :],dtype=torch.float32)\n",
    "\n",
    "        tr_labels = torch.tensor(dx_list[tr_index.long()])\n",
    "        val_labels = torch.tensor(dx_list[val_index.long()])\n",
    "        test_labels = torch.tensor(dx_list[test_index.long()])\n",
    "\n",
    "        tr_labels = tr_labels.to(device)\n",
    "        val_labels = val_labels.to(device)\n",
    "        test_labels = test_labels.to(device)\n",
    "\n",
    "\n",
    "        tr_eps = tr_eps.to(device)\n",
    "        # val_eps = val_eps.to(device)\n",
    "        test_eps = test_eps.to(device)\n",
    "\n",
    "        print('tr_eps',tr_eps.shape,tr_eps.dtype)\n",
    "        print('val_eps',val_eps.shape,val_eps.dtype)\n",
    "        print('test_eps',test_eps.shape,test_eps.dtype)\n",
    "\n",
    "        print('tr_labels',tr_labels.shape,tr_labels.dtype)\n",
    "        print('val_labels',val_labels.shape,val_labels.dtype)\n",
    "        print('test_labels',test_labels.shape,test_labels.dtype)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        observation_shape = finalData.shape\n",
    "        L=\"\"\n",
    "        lmax=\"\"\n",
    "        number_of_graph_channels = 1\n",
    "        if args.model_type == \"graph_the_works\":\n",
    "            print('obs shape',observation_shape[3])\n",
    "            encoder = NatureCNN(observation_shape[3], args)\n",
    "\n",
    "            encoder.to(device)\n",
    "            lstm_model = subjLSTM(device, sample_y, args.lstm_size, num_layers=args.lstm_layers,\n",
    "                                  freeze_embeddings=True, gain=current_gain,bidrection=True)\n",
    "            dir = \"\"\n",
    "            if args.pre_training == \"DECENNT\":\n",
    "                dir = 'Pre_Trained/DECENNT/UsingHCP500TP/model.pt'\n",
    "                args.oldpath = wpath1 + '/Pre_Trained/DECENNT/UsingHCP500TP'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        complete_model = combinedModel(encoder,lstm_model, samples_per_subject, gain=current_gain, PT=args.pre_training, exp=args.exp, device_one=device, oldpath=args.oldpath,n_regions=n_regions,device_two=device2,device_zero=device2,device_extra=device2 )\n",
    "        complete_model.to(device)\n",
    "        config = {}\n",
    "        config.update(vars(args))\n",
    "        # print(\"trainershape\", os.path.join(wandb.run.dir, config['env_name'] + '.pt'))\n",
    "        config['obs_space'] = observation_shape  # weird hack\n",
    "        if args.method == \"graph_the_works\":\n",
    "            trainer = the_works_trainer(complete_model, config, device=device2, device_encoder=device,\n",
    "                                        tr_labels=tr_labels,\n",
    "                                  val_labels=val_labels, test_labels=test_labels, trial=str(trial),\n",
    "                                        crossv=str(test_ID),gtrial=str(g_trial))\n",
    "\n",
    "        else:\n",
    "            assert False, \"method {} has no trainer\".format(args.method)\n",
    "        results[result_counter][0], results[result_counter][1], results[result_counter][2], \\\n",
    "        results[result_counter][3],results[result_counter][4],\\\n",
    "        results[result_counter][5], _ = trainer.train(tr_eps, val_eps, test_eps)\n",
    "\n",
    "        \n",
    "        #ipdb>  print(batch_sizes.dtype)\n",
    "        #torch.int64\n",
    "        #ipdb>  print(input.dtype)\n",
    "        #torch.float64\n",
    "        result_counter = result_counter + 1\n",
    "        tresult_csv = os.path.join(args.path, 'test_results' + sID + '.csv')\n",
    "        np.savetxt(tresult_csv, results.numpy(), delimiter=\",\")\n",
    "\n",
    "np_results = results.numpy()\n",
    "auc = np_results[:,1]\n",
    "acc = np_results[:, 0]\n",
    "print('mean test auc = ', np.mean(acc[:]))\n",
    "print('mean test acc = ', np.mean(auc[:]))\n",
    "\n",
    "tresult_csv = os.path.join(args.path, 'test_results' + sID + '.csv')\n",
    "np.savetxt(tresult_csv, np_results, delimiter=\",\")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print('total time = ', elapsed);\n",
    "\n",
    "\n",
    "# ipdb>  input.shape\n",
    "# torch.Size([5, 129600]) ### 129600 is 360^2\n",
    "# ipdb>  weight.t().shape\n",
    "# torch.Size([10000, 64])\n",
    "\n",
    "#complete_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c349c-9b51-44dc-a223-254fbe96222d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
